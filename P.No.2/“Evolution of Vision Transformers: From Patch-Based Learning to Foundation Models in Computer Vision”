
**1) Vision Transformer (ViT)**

* **ููุณูุฏฺฏุงู:** Alexey Dosovitskiy ู ููฺฉุงุฑุงู
* **ุณุงู / ูุญู ุงูุชุดุงุฑ:** 2020, ICLR (arXiv)
* **ููฺฉ / ฺฉุฏ:** [arXiv](https://arxiv.org/abs/2010.11929), [GitHub](https://github.com/google-research/vision_transformer)
* **ุฎูุงุตู:** ุชุตูุฑ ุจู ูพฺโูุง 16x16 ุชูุณู ูโุดูุฏ ู ุจู ุชุฑูุณููุฑูุฑ ุฏุงุฏู ูโุดูุฏุ ุจุฏูู CNN ุฏูุช ุจุงูุง ุฏุงุฑุฏ.
* **ุฏุชุงุณุช:** JFT-300M (ูพุดโุขููุฒุด)ุ ImageNet
* **ูพูุชูุฑู:** PyTorch / JAX

**2) Swin Transformer**

* **ููุณูุฏฺฏุงู:** Ze Liu ู ููฺฉุงุฑุงู
* **ุณุงู / ูุญู ุงูุชุดุงุฑ:** 2021, ICCV (arXiv)
* **ููฺฉ / ฺฉุฏ:** [arXiv](https://arxiv.org/abs/2103.14030), [GitHub](https://github.com/microsoft/Swin-Transformer)
* **ุฎูุงุตู:** ุจุง ูพูุฌุฑูโูุง ุดูุชโุดููุฏูุ ูุญุงุณุจุงุช attention ูุญู ู ฺฉุงุฑุขูุฏ ุงูุฌุงู ูโุดูุฏ ู ุงุฑุชุจุงุท ุจู ูพูุฌุฑูโูุง ุญูุธ ูโุดูุฏ.
* **ุฏุชุงุณุช:** ImageNet, COCO, ADE20K
* **ูพูุชูุฑู:** PyTorch

**3) Masked Autoencoders (MAE)**

* **ููุณูุฏฺฏุงู:** Kaiming He ู ููฺฉุงุฑุงู
* **ุณุงู / ูุญู ุงูุชุดุงุฑ:** 2022, CVPR (arXiv)
* **ุฎูุงุตู:** ุจุฎุดโูุง ุงุฒ ุชุตูุฑ ูุงุณฺฉ ูโุดููุฏ ู ูุฏู ุขูโูุง ุฑุง ุจุงุฒุณุงุฒ ูโฺฉูุฏุ ูพุดโุขููุฒุด ุฎูุฏูุธุงุฑุช ูุคุซุฑ ู ูุงุจู ุงูุชูุงู.
* **ุฏุชุงุณุช:** ImageNet-1K
* **ูพูุชูุฑู:** PyTorch

**4) Segment Anything (SAM)**

* **ููุณูุฏฺฏุงู:** Alexander Kirillov ู ููฺฉุงุฑุงู
* **ุณุงู / ูุญู ุงูุชุดุงุฑ:** 2023, ICCV (arXiv)
* **ุฎูุงุตู:** ูุฏู ูพุงู ุชูุณูโุจูุฏ ฺฉู ุจุง ูพุฑุงููพุชุ ุชูุฑุจุงู ูุฑ ุดุก ุฑุง ุงุฒ ุชุตูุฑ ุฌุฏุง ูโฺฉูุฏุ ุขููุฒุด ุฑู SA-1B.
* **ุฏุชุงุณุช:** SA-1B (ฑ ููุงุฑุฏ ูุงุณฺฉ)
* **ูพูุชูุฑู:** PyTorch
* **ููฺฉ / ฺฉุฏ:** [arXiv](https://arxiv.org/abs/2304.02643), [GitHub](https://github.com/facebookresearch/segment-anything)

**5) DINOv2**

* **ููุณูุฏฺฏุงู:** Maxime Oquab ู ููฺฉุงุฑุงู
* **ุณุงู / ูุญู ุงูุชุดุงุฑ:** 2023, arXiv
* **ุฎูุงุตู:** ุจุง ุงุฏฺฏุฑ ุฎูุฏูุธุงุฑุช ู ุฏุชุงุณุช ุจุฒุฑฺฏุ ูฺฺฏโูุง ุนููู ุชููุฏ ูโฺฉูุฏ ฺฉู ุจุฏูู ูุงูโุชูู ุฑู ูุธุงู ูุฎุชูู ููโุงูุฏ.
* **ุฏุชุงุณุช:** ~142M ุชุตูุฑ ุจุฏูู ุจุฑฺุณุจ
* **ูพูุชูุฑู:** PyTorch
* **ฺฉุฏ:** [GitHub](https://github.com/facebookresearch/dinov2)

**๐ ูฺฉุงุช ฺฉูุฏ ู ุฑููุฏ:**

* ููู ูุฏูโูุง ุฑู ุงุฏฺฏุฑ ุนูู ุจูุง ู ุชุฑูุณููุฑูุฑ ุชูุฑฺฉุฒ ุฏุงุฑูุฏ.
* ุณุฑ ูพุดุฑูุช: ViT โ Swin โ MAE โ SAM โ DINOv2
* ูุญูุฑ ุงุตู: ุชุฑูุณููุฑูุฑูุงุ ูพุดโุขููุฒุด ุฎูุฏูุธุงุฑุชุ ุงุณุชุฎุฑุงุฌ ูฺฺฏโูุง ุนูููุ ูุฏู ูพุงู ู ฺูุฏููุธูุฑู.

**๐ง ต ูุงฺู ฺฉูุฏ:**

1. Transformer Architecture
2. Self-Supervised Learning
3. Representation Learning
4. Foundation Models
5. Vision Transformer (ViT)

